{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f969d6cb",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3387826",
   "metadata": {},
   "source": [
    "## importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c46e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693dbe2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>price</th>\n",
       "      <th>stock</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>mobile</th>\n",
       "      <th>avatar_id</th>\n",
       "      <th>group</th>\n",
       "      <th>brand</th>\n",
       "      <th>parking</th>\n",
       "      <th>pool</th>\n",
       "      <th>children_policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>969</td>\n",
       "      <td>73</td>\n",
       "      <td>56</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>44</td>\n",
       "      <td>dutch</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Accar Hotels</td>\n",
       "      <td>Ibas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>760</td>\n",
       "      <td>154</td>\n",
       "      <td>196</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>44</td>\n",
       "      <td>dutch</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Yin Yang</td>\n",
       "      <td>Royal Lotus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570</td>\n",
       "      <td>93</td>\n",
       "      <td>112</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>44</td>\n",
       "      <td>dutch</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Independant</td>\n",
       "      <td>Independant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>835</td>\n",
       "      <td>97</td>\n",
       "      <td>113</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>44</td>\n",
       "      <td>dutch</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Independant</td>\n",
       "      <td>Independant</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680</td>\n",
       "      <td>131</td>\n",
       "      <td>55</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>44</td>\n",
       "      <td>dutch</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Independant</td>\n",
       "      <td>Independant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>177</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>vilnius</td>\n",
       "      <td>0</td>\n",
       "      <td>greek</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Accar Hotels</td>\n",
       "      <td>Marcure</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>47</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>vilnius</td>\n",
       "      <td>0</td>\n",
       "      <td>greek</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Accar Hotels</td>\n",
       "      <td>Marcure</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>187</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>vilnius</td>\n",
       "      <td>0</td>\n",
       "      <td>greek</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Accar Hotels</td>\n",
       "      <td>Marcure</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>vilnius</td>\n",
       "      <td>0</td>\n",
       "      <td>greek</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Boss Western</td>\n",
       "      <td>Boss Western</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>197</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>vilnius</td>\n",
       "      <td>0</td>\n",
       "      <td>greek</td>\n",
       "      <td>0</td>\n",
       "      <td>111612</td>\n",
       "      <td>Boss Western</td>\n",
       "      <td>J.Halliday Inn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94710 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hotel_id  price  stock       city  date language  mobile  avatar_id  \\\n",
       "0        969     73     56  amsterdam    44    dutch       0     111612   \n",
       "1        760    154    196  amsterdam    44    dutch       0     111612   \n",
       "2        570     93    112  amsterdam    44    dutch       0     111612   \n",
       "3        835     97    113  amsterdam    44    dutch       0     111612   \n",
       "4        680    131     55  amsterdam    44    dutch       0     111612   \n",
       "..       ...    ...    ...        ...   ...      ...     ...        ...   \n",
       "88       177    164      0    vilnius     0    greek       0     111612   \n",
       "89        47    163      0    vilnius     0    greek       0     111612   \n",
       "90       187    168      0    vilnius     0    greek       0     111612   \n",
       "91       136    140      0    vilnius     0    greek       0     111612   \n",
       "92       197    119      0    vilnius     0    greek       0     111612   \n",
       "\n",
       "           group           brand  parking  pool  children_policy  \n",
       "0   Accar Hotels            Ibas        1     0                0  \n",
       "1       Yin Yang     Royal Lotus        0     0                0  \n",
       "2    Independant     Independant        1     0                0  \n",
       "3    Independant     Independant        0     0                0  \n",
       "4    Independant     Independant        1     0                0  \n",
       "..           ...             ...      ...   ...              ...  \n",
       "88  Accar Hotels         Marcure        0     1                0  \n",
       "89  Accar Hotels         Marcure        1     0                0  \n",
       "90  Accar Hotels         Marcure        1     1                0  \n",
       "91  Boss Western    Boss Western        0     0                0  \n",
       "92  Boss Western  J.Halliday Inn        1     0                0  \n",
       "\n",
       "[94710 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels = pd.read_csv('features_hotels.csv', index_col=['hotel_id', 'city'])\n",
    "pricing_requests = pd.read_csv(\"price_dataset1.csv\",index_col =0)\n",
    "pricing_requests = pricing_requests.join(hotels, on=['hotel_id', 'city'])\n",
    "pricing_requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff5a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataset(dataset, test_ratio=0.30):\n",
    "#   \"\"\"Splits a panda dataframe in two.\"\"\"\n",
    "#   test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "#   return dataset[~test_indices], dataset[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3501743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_pd, test_ds_pd = split_dataset(pricing_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1934016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:43:51.023438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 10:43:51.122244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/insa/lib:$LD_LIBRARY_PATH\n",
      "2022-11-23 10:43:51.122264: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-23 10:43:53.076625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/insa/lib:$LD_LIBRARY_PATH\n",
      "2022-11-23 10:43:53.076675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/insa/lib:$LD_LIBRARY_PATH\n",
      "2022-11-23 10:43:53.076679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/insa/anaconda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e22f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:43:57.295966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/insa/lib:$LD_LIBRARY_PATH\n",
      "2022-11-23 10:43:57.295998: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-23 10:43:57.296017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (insa-12588): /proc/driver/nvidia/version does not exist\n",
      "2022-11-23 10:43:57.296285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "label =\"price\"\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(pricing_requests, label=label, task=tfdf.keras.Task.REGRESSION)\n",
    "# test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f75b5",
   "metadata": {},
   "source": [
    "## Tuner potentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b2c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configure the tuner.\n",
    "\n",
    "# # Create a Random Search tuner with 50 trials.\n",
    "# tuner = tfdf.tuner.RandomSearch(num_trials=50)\n",
    "\n",
    "# # Define the search space.\n",
    "# #\n",
    "# # Adding more parameters generaly improve the quality of the model, but make\n",
    "# # the tuning last longer.\n",
    "\n",
    "# tuner.choice(\"min_examples\", [2, 5, 7, 10])\n",
    "# tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "\n",
    "# # Some hyper-parameters are only valid for specific values of other\n",
    "# # hyper-parameters. For example, the \"max_depth\" parameter is mostly useful when\n",
    "# # \"growing_strategy=LOCAL\" while \"max_num_nodes\" is better suited when\n",
    "# # \"growing_strategy=BEST_FIRST_GLOBAL\".\n",
    "\n",
    "# local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "# local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n",
    "\n",
    "# # merge=True indicates that the parameter (here \"growing_strategy\") is already\n",
    "# # defined, and that new values are added to it.\n",
    "# global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
    "# global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
    "\n",
    "# tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "# tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\n",
    "# tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "\n",
    "# # Uncomment some (or all) of the following hyper-parameters to increase the\n",
    "# # quality of the search. The number of trial should be increased accordingly.\n",
    "\n",
    "# # tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "# # oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
    "# # oblique_space.choice(\"sparse_oblique_normalization\",\n",
    "# #                      [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n",
    "# # oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "# # oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ec41d",
   "metadata": {},
   "source": [
    "## Compilation et prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65cc1385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpglckpswa as temporary training directory\n",
      "WARNING:tensorflow:From /home/brosset/.local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/brosset/.local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "[INFO 2022-11-23T10:44:09.20857423+01:00 kernel.cc:1175] Loading model from path /tmp/tmpglckpswa/model/ with prefix 910c681a45c341e6\n",
      "[INFO 2022-11-23T10:44:13.25195278+01:00 abstract_model.cc:1306] Engine \"RandomForestOptPred\" built\n",
      "[INFO 2022-11-23T10:44:13.251982737+01:00 kernel.cc:1021] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f850aeb21f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f850aeb21f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f850aeb21f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f850ae87220>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
    "model.compile(metrics=[\"mse\"])\n",
    "model.fit(x=train_ds, verbose =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909140a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation = model.evaluate(test_ds ,return_dict=True)\n",
    "# si on a split nos données\n",
    "\n",
    "# print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c7551ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 82ms/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_set.csv\",index_col=0)\n",
    "\n",
    "test = test.join(hotels, on=['hotel_id', 'city'])\n",
    "\n",
    "test = test.drop([\"order_requests\"],axis =1)\n",
    "\n",
    "test_df = tfdf.keras.pd_dataframe_to_tf_dataset(test)\n",
    "\n",
    "A =model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e265a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame(A)\n",
    "\n",
    "Submission.to_csv(\"submission1.csv\",header = [\"price\"],index_label=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765084f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
